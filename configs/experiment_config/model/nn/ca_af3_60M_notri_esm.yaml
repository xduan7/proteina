name: ca_af3  # name of architecture

# Architecture parameters
token_dim: 512  # dimension of the tokens in the sequence
nlayers: 10  # number of transformer layers
nheads: 8  # number of attn heads
residual_mha: True  # whether to use a residual connection in the mha
residual_transition: True  # whether to use a residual connection in the transition
parallel_mha_transition: False  # whether to compute mha and transition as parallel and add them up (AF3 style) or sequentially (normal transofrmers)
use_attn_pair_bias: True  # whether to bias attention using a bias coming from a pair representation

strict_feats: False  # if False, then fills missing features with default values (e.g. chain break with zero, residue sequence index by [0, 1, 2, ...], etc)
# If True, if some feature is not provided, then it raises an error

# List of all available sequence features:
#   "res_seq_pdb_idx", requires transform ResidueSequencePositionPdbTransform
#   "time_emb"
#   "chain_break_per_res", requires transform ChainBreakPerResidueTransform
#   "x_sc"
#   "fold_emb"
feats_init_seq: ["res_seq_pdb_idx", "chain_break_per_res", "x_sc", "esm_seq"]  # Sequence features to include in initial representation
feats_cond_seq: ["time_emb", "fold_emb"]  # Sequence features to include in conditioning variables


# Parameters for the features we extract (both for sequence representation and conditioning vector)
t_emb_dim: 256  # dimension of the time embedding
dim_cond: 512  # dimension of conditioning vector
idx_emb_dim: 128  # dimension of the sequence position [0, 1, 2, ...] (if contiguous residues) embeddings
fold_emb_dim: 256  # dimension of fold class embedding. This will be multiplied by three, as we have C, A, T embeddings.
esm_model_name: "esm2_t33_650M_UR50D"  # name of the esm model to use (FoldFlow uses esm2_t33_650M_UR50D)
esm_repr_layers: null  # layers to use for the esm representation; null means all layers
cath_code_dir: ${oc.env:DATA_PATH}/pdb_raw/    # This should be set as the path to your pdb_cath dataset directory
multilabel_mode: "sample"


# List of all available sequence features:
#   "xt_pair_dists"
#   "x_sc_pair_dists"
#   "rel_seq_sep"
#   "time_emb"
feats_pair_repr: ["rel_seq_sep", "x_sc_pair_dists", "xt_pair_dists", "esm_attn_map"]  # Features to include in the pair representation
feats_pair_cond: ["time_emb"]  # Features to include in the pair representation conditioning


# Parameters for the pair features we extract
# Binning for the pair distances of noisy xt
xt_pair_dist_dim: 64
xt_pair_dist_min: 0.1  # in nm (not Å)
xt_pair_dist_max: 3  # in nm (not Å)
# Binning for the pair distances for self conditioning
x_sc_pair_dist_dim: 128
x_sc_pair_dist_min: 0.1  # in nm (not Å)
x_sc_pair_dist_max: 3  # in nm (not Å)
# Motif Conditioning
x_motif_pair_dist_dim: 128
x_motif_pair_dist_min: 0.1  # in nm (not Å)
x_motif_pair_dist_max: 3  # in nm (not Å)
# Relative sequence separation
seq_sep_dim: 127  # should be odd >= 5
# Dimension of final pair representation
pair_repr_dim: 256


# Newer stuff for exploration
update_pair_repr: False  # whether to update pair representation, automatically overridden to False if `use_attn_pair_bias: False`
update_pair_repr_every_n: 2  # Update the pair representation every n layers -> For 15 layers we get 5 pair updates (if update pair representation is true)
use_tri_mult: False  # whether to use triangular multiplication layers in pair update, ignored if not updating pair representation

num_registers: 10
use_qkln: True

num_buckets_predict_pair: 64